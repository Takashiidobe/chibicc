diff --git a/src/codegen.rs b/src/codegen.rs
index cca4e19..f02ca0f 100644
--- a/src/codegen.rs
+++ b/src/codegen.rs
@@ -64,18 +64,34 @@ impl<'a> Codegen<'a> {
     fn data_sections(&self) {
         for binding in &self.su {
             let binding = binding.borrow();
-            if let BindingKind::GlobalVar = binding.kind {
+            if let BindingKind::GlobalVar { init_data } = &binding.kind {
                 let name = String::from_utf8_lossy(&binding.name);
                 println!("  .data");
                 println!("  .globl {}", name);
                 println!("{}:", name);
-                println!("  .zero {}", binding.ty.size);
+                if let Some(init_data) = init_data {
+                    print!("  .byte ");
+                    let mut it = init_data.iter().peekable();
+                    while let Some(b) = it.next() {
+                        if it.peek().is_none() {
+                            println!("{}", b);
+                        }
+                        else {
+                            print!("{},", b);
+                        }
+                    }
+                }
+                else {
+                    println!("  .zero {}", binding.ty.size);
+                }
             }
         }
     }
 
     fn text_section(&mut self) {
         // This still sucks... just less than before
+        println!();
+        println!("  .text");
         for i in 0..self.su.len() {
             let decl = self.su[i].clone();
             let decl = decl.borrow();
@@ -319,11 +335,11 @@ impl<'a> Codegen<'a> {
         match &expr.kind {
             ExprKind::Var(data) => {
                 let data = data.borrow();
-                match data.kind {
+                match &data.kind {
                     BindingKind::LocalVar { stack_offset } => {
                         println!("  lea {}(%rbp), %rax", stack_offset);
                     }
-                    BindingKind::GlobalVar => {
+                    BindingKind::GlobalVar {..} => {
                         println!("  lea {}(%rip), %rax", String::from_utf8_lossy(&data.name));
                     }
                     _ => panic!("Unsupported")
diff --git a/src/lexer.rs b/src/lexer.rs
index 867da89..a9b8529 100644
--- a/src/lexer.rs
+++ b/src/lexer.rs
@@ -1,6 +1,6 @@
 use std::collections::HashSet;
 
-use crate::errors::ErrorReporting;
+use crate::{errors::ErrorReporting, parser::AsciiStr};
 
 #[derive(Debug)]
 pub enum TokenKind {
@@ -8,6 +8,7 @@ pub enum TokenKind {
     Ident,
     Keyword,
     Num(i64),
+    Str(AsciiStr),
     Eof
 }
 
@@ -31,7 +32,7 @@ lazy_static! {
 }
 
 pub struct Lexer<'a> {
-    src: &'a [u8],
+    src: &'a [u8]
 }
 
 impl<'a> ErrorReporting for Lexer<'a> {
@@ -43,12 +44,12 @@ impl<'a> Lexer<'a> {
         Self { src }
     }
 
-    pub fn tokenize(&self) -> Vec<Token> {
+    pub fn tokenize(&mut self) -> Vec<Token> {
         let mut toks = Vec::new();
         let mut offset = 0;
         let src = self.src;
 
-        while offset < src.len() {
+        while src[offset] != 0 {
             let c = src[offset];
 
             if c.is_ascii_whitespace() {
@@ -67,23 +68,44 @@ impl<'a> Lexer<'a> {
                 offset += count;
             }
             else if is_ident_start(c) {
-              let start_offset = offset;
-              loop {
-                  offset += 1;
-                  if !is_ident_cont(src[offset]) { break; }
-              }
-              let name = &src[start_offset..offset];
-              let kind = if KEYWORDS.contains(&name) {
-                  TokenKind::Keyword
-              }
-              else {
-                  TokenKind::Ident
-              };
-              toks.push(Token {
-                  offset: start_offset,
-                  length: offset - start_offset,
-                  kind,
-              });
+                let start_offset = offset;
+                loop {
+                    offset += 1;
+                    if !is_ident_cont(src[offset]) { break; }
+                }
+                let name = &src[start_offset..offset];
+                let kind = if KEYWORDS.contains(&name) {
+                    TokenKind::Keyword
+                }
+                else {
+                    TokenKind::Ident
+                };
+                toks.push(Token {
+                    offset: start_offset,
+                    length: offset - start_offset,
+                    kind,
+                });
+            }
+            else if c == b'"' {
+                let start_offset = offset;
+                offset += 1;
+
+                let mut str = Vec::new();
+                while src[offset] != b'"' {
+                    if src[offset] == b'\n' || src[offset] == 0 {
+                        self.error_at(start_offset, "unclosed literal string");
+                    }
+                    str.push(src[offset]);
+                    offset += 1;
+                }
+                offset += 1;
+                str.push(0);
+
+                toks.push(Token {
+                    offset,
+                    length: offset - start_offset,
+                    kind: TokenKind::Str(str),
+                });
             }
             else {
                 let punct_len = read_punct(&src[offset..]);
diff --git a/src/main.rs b/src/main.rs
index 57c50ff..b0cde7d 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -16,17 +16,20 @@ fn main() {
         panic!("{}: invalid number of arguments", args[0]);
     }
 
-    let src = args[1].as_bytes();
+    let mut src = args[1].as_bytes().to_vec();
 
-    let lexer = Lexer::new(src);
+    // It's nice to have a sentinel value so we don't have to keep checking bounds
+    src.push(0);
+
+    let mut lexer = Lexer::new(&src);
 
     let toks = lexer.tokenize();
 
-    let mut parser = Parser::new(src, &toks);
+    let mut parser = Parser::new(&src, &toks);
 
     let su = parser.source_unit();
     parser.ensure_done();
 
-    let mut codegen = Codegen::new(src, su);
+    let mut codegen = Codegen::new(&src, su);
     codegen.program();
 }
\ No newline at end of file
diff --git a/src/parser.rs b/src/parser.rs
index 1259ec0..de6ec1c 100644
--- a/src/parser.rs
+++ b/src/parser.rs
@@ -1,4 +1,5 @@
 use std::cell::RefCell;
+
 use std::rc::Rc;
 
 use crate::lexer::{Token, TokenKind};
@@ -74,7 +75,7 @@ pub struct Function {
 
 #[derive(Debug)]
 pub enum BindingKind {
-    GlobalVar,
+    GlobalVar { init_data: Option<Vec<u8>> },
     LocalVar { stack_offset: i64 },
     Function(Function),
 }
@@ -130,6 +131,7 @@ pub struct Parser<'a> {
     tok_index: usize,
     local_vars: Vec<SP<Binding>>,
     global_vars: Vec<SP<Binding>>,
+    next_unique_id: u64,
 }
 
 impl<'a> ErrorReporting for Parser<'a> {
@@ -146,30 +148,31 @@ impl<'a> Parser<'a> {
             toks,
             tok_index: 0,
             local_vars: Vec::new(),
-            global_vars: Vec::new()
+            global_vars: Vec::new(),
+            next_unique_id: 0
         }
     }
 
     // source_unit = stmt+
     pub fn source_unit(&mut self) -> SourceUnit {
-        let mut su = Vec::new();
         loop {
             match self.peek().kind {
                 TokenKind::Eof => break,
                 _ => {
                     if self.is_function() {
-                        su.push(Rc::new(RefCell::new(self.function())))
+                        self.function();
                     }
                     else {
-                        self.global_vars(&mut su);
+                        self.global_vars();
                     }
                 },
             }
         }
-        su
+        // TODO Any method to "reset the member vector and return a new vec not owned by the struct without cloning"?
+        self.global_vars.clone()
     }
 
-    fn global_vars(&mut self, bindings: &mut Vec<SP<Binding>>) {
+    fn global_vars(&mut self) {
         let base_ty = self.declspec();
 
         let mut first = true;
@@ -181,10 +184,9 @@ impl<'a> Parser<'a> {
 
             let offset = self.peek().offset;
             let (ty, name) = self.declarator(base_ty.clone());
-            let gvar = Binding { kind: BindingKind::GlobalVar, name, ty, offset };
+            let gvar = Binding { kind: BindingKind::GlobalVar { init_data: None }, name, ty, offset };
             let binding = Rc::new(RefCell::new(gvar));
             self.global_vars.push(binding.clone());
-            bindings.push(binding);
         }
         self.skip(";");
     }
@@ -203,7 +205,7 @@ impl<'a> Parser<'a> {
         matches!(ty.kind, TyKind::Fn(_, _))
     }
 
-    fn function(&mut self) -> Binding {
+    fn function(&mut self) {
         self.local_vars.clear();
 
         let offset = self.peek().offset;
@@ -215,7 +217,7 @@ impl<'a> Parser<'a> {
         let body = self.compound_stmt();
         // Reverse them to keep the locals layout in line with chibicc
         let locals: Vec<SP<Binding>> = self.local_vars.clone().into_iter().rev().collect();
-        Binding {
+        self.global_vars.push(Rc::new(RefCell::new(Binding {
             kind: BindingKind::Function(Function {
                 params,
                 locals,
@@ -225,7 +227,7 @@ impl<'a> Parser<'a> {
             name,
             ty,
             offset,
-        }
+        })));
     }
 
     // stmt = "return" expr ";"
@@ -689,7 +691,7 @@ impl<'a> Parser<'a> {
         node
     }
 
-    // primary = "(" expr ")" | "sizeof" unary | funcall | num
+    // primary = "(" expr ")" | "sizeof" unary | funcall | num | str
     fn primary(&mut self) -> ExprNode {
         match self.peek().kind {
             TokenKind::Num(val) => {
@@ -703,6 +705,24 @@ impl<'a> Parser<'a> {
                     return synth_num(node.ty.size.try_into().unwrap(), node.offset);
                 }
             }
+            TokenKind::Str(ref str) => {
+                let ty = Ty::array(Ty::char(), str.len());
+                let init_data = Some(str.to_owned());
+                let offset = self.advance().offset;
+                let name = self.mk_unique_id(".L..");
+                let binding = Rc::new(RefCell::new(Binding {
+                    kind: BindingKind::GlobalVar { init_data },
+                    name,
+                    ty: ty.clone(),
+                    offset
+                }));
+                self.global_vars.push(binding.clone());
+                return ExprNode {
+                    kind: ExprKind::Var(binding),
+                    offset,
+                    ty,
+                }
+            }
             TokenKind::Ident => {
                 if self.la_is(1, "(") {
                     return self.funcall();
@@ -827,6 +847,12 @@ impl<'a> Parser<'a> {
         ExprNode { kind: ExprKind::Deref(expr), offset, ty }
     }
 
+    fn mk_unique_id(&mut self, prefix: &str) -> AsciiStr {
+        let res = format!("{}{}", prefix, self.next_unique_id);
+        self.next_unique_id += 1;
+        res.into_bytes()
+    }
+
     #[allow(dead_code)]
     fn src_rest(&self) -> std::borrow::Cow<str> {
         String::from_utf8_lossy(&self.src[self.peek().offset..])
diff --git a/test.sh b/test.sh
index 26bc32b..6a4d707 100755
--- a/test.sh
+++ b/test.sh
@@ -175,6 +175,15 @@ assert 1 'int main() { char x; return sizeof(x); }'
 assert 10 'int main() { char x[10]; return sizeof(x); }'
 assert 1 'int main() { return sub_char(7, 3, 3); } int sub_char(char a, char b, char c) { return a-b-c; }'
 
+assert 0 'int main() { return ""[0]; }'
+assert 1 'int main() { return sizeof(""); }'
+
+assert 97 'int main() { return "abc"[0]; }'
+assert 98 'int main() { return "abc"[1]; }'
+assert 99 'int main() { return "abc"[2]; }'
+assert 0 'int main() { return "abc"[3]; }'
+assert 4 'int main() { return sizeof("abc"); }'
+
 rm -f tmp tmp2.o tmp.s
 
 echo OK
